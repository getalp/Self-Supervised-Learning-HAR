{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl \n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "randomSeed = 0\n",
    "np.random.seed(randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDir = './Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetList = ['HHAR','MobiAct','MotionSense','RealWorld_Waist','UCI','PAMAP'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName =  mainDir + 'SSL_PipelineUnionV2/LODO'\n",
    "os.makedirs(dirName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneDir = 'fineTuneData'\n",
    "testDir = 'testData'\n",
    "valDir = 'valData'\n",
    "datasetDir = 'datasets'\n",
    "# os.makedirs(dirName+'/'+datasetDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+fineTuneDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+testDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+valDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneData = []\n",
    "fineTuneLabel = []\n",
    "\n",
    "for datasetIndex,dataSetName in enumerate(datasetList):\n",
    "    datasetLabel = hkl.load(mainDir + 'datasetClientsUnion/'+dataSetName+'/clientsLabel.hkl')\n",
    "    datasetTrain = hkl.load(mainDir + 'datasetClientsUnion/'+dataSetName+'/clientsData.hkl')\n",
    "#     hkl.dump(datasetTrain,dirName+'/'+datasetDir+ '/'+dataSetName+'_data.hkl')\n",
    "#     hkl.dump(datasetLabel,dirName+'/'+datasetDir+ '/'+dataSetName+'_label.hkl')\n",
    "    trainingData = []\n",
    "    testingData = []\n",
    "    validatingData = []\n",
    "    \n",
    "    trainingLabel = []\n",
    "    testingLabel = []\n",
    "    validatingLabel = []\n",
    "    \n",
    "    for datasetData, datasetLabels in zip(datasetTrain,datasetLabel):\n",
    "        nonSoftMaxedLabels = np.argmax(datasetLabels,axis = -1)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10,shuffle = False)\n",
    "        skf.get_n_splits(datasetData, nonSoftMaxedLabels)\n",
    "        partitionedData = list()\n",
    "        partitionedLabel = list()\n",
    "        testIndex = []\n",
    "        \n",
    "        for train_index, test_index in skf.split(datasetData, nonSoftMaxedLabels):\n",
    "            testIndex.append(test_index)\n",
    "\n",
    "        trainIndex = np.hstack((testIndex[:7]))\n",
    "        devIndex = testIndex[8]\n",
    "        testIndex = np.hstack((testIndex[8:]))\n",
    "\n",
    "        X_train = tf.gather(datasetData,trainIndex).numpy()\n",
    "        X_val = tf.gather(datasetData,devIndex).numpy()\n",
    "        X_test = tf.gather(datasetData,testIndex).numpy()\n",
    "\n",
    "        y_train = tf.gather(nonSoftMaxedLabels,trainIndex).numpy()\n",
    "        y_val = tf.gather(nonSoftMaxedLabels,devIndex).numpy()\n",
    "        y_test = tf.gather(nonSoftMaxedLabels,testIndex).numpy()\n",
    "        \n",
    "        y_train = tf.one_hot(y_train,10)\n",
    "        y_val = tf.one_hot(y_val,10)\n",
    "        y_test = tf.one_hot(y_test,10)\n",
    "\n",
    "        trainingData.append(X_train)\n",
    "        validatingData.append(X_val)\n",
    "        testingData.append(X_test)\n",
    "        \n",
    "        trainingLabel.append(y_train)\n",
    "        validatingLabel.append(y_val)\n",
    "        testingLabel.append(y_test)\n",
    "        \n",
    "        \n",
    "    # testingLabel = np.asarray(testingLabel)\n",
    "    # testingData = np.asarray(testingData)\n",
    "    \n",
    "    # validatingData = np.asarray(validatingData)\n",
    "    # validatingLabel = np.asarray(validatingLabel)\n",
    "\n",
    "    # trainingLabel = np.asarray(trainingLabel)\n",
    "    # trainingData = np.asarray(trainingData)\n",
    "    \n",
    "    fineTuneData.append(trainingData)\n",
    "    fineTuneLabel.append(trainingLabel)\n",
    "\n",
    "    hkl.dump(trainingData,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_all_samples_data.hkl')\n",
    "    hkl.dump(trainingLabel,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_all_samples_label.hkl')\n",
    "    hkl.dump(testingData,dirName+'/'+testDir+ '/'+dataSetName+'_data.hkl' )\n",
    "    hkl.dump(testingLabel,dirName+'/'+testDir+ '/'+dataSetName+'_label.hkl' )\n",
    "    hkl.dump(validatingData,dirName+'/'+valDir+ '/'+dataSetName+'_data.hkl' )\n",
    "    hkl.dump(validatingLabel,dirName+'/'+valDir+ '/'+dataSetName+'_label.hkl' )\n",
    "# fineTuneData = np.asarray(fineTuneData)\n",
    "# fineTuneLabel = np.asarray(fineTuneLabel)\n",
    "\n",
    "\n",
    "dirName+'/'+fineTuneDir+ '/'+dataSetName+'_All_samples_data.hkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneSamples = [100, 50, 25, 10, 5, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fineTuneData = np.vstack((np.hstack((fineTuneData))))\n",
    "# fineTuneLabel = np.vstack((np.hstack((fineTuneLabel))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.random.default_rng()\n",
    "\n",
    "for index, (trainingDataSubject, traningLabelSubject) in enumerate(zip(fineTuneData,fineTuneLabel)):\n",
    "\n",
    "    stackedData =  np.vstack(trainingDataSubject)\n",
    "    stackedLabel = np.vstack(traningLabelSubject)\n",
    "    stackedSoftMaxLabels = np.argmax(stackedLabel,axis = -1).ravel()\n",
    "    uniqueLabels = np.unique(stackedSoftMaxLabels)\n",
    "    \n",
    "    datasetXSamples = {new_list: [] for new_list in fineTuneSamples}\n",
    "    datasetYSamples = {new_list: [] for new_list in fineTuneSamples}\n",
    "\n",
    "    for labels in uniqueLabels:\n",
    "        labelLocation = np.where(stackedSoftMaxLabels == labels)[0]\n",
    "        labelLocation = gen.choice(labelLocation, np.max(fineTuneSamples), replace=False)\n",
    "        for sampleCount in fineTuneSamples:\n",
    "            datasetXSamples[sampleCount].append(stackedData[labelLocation][:sampleCount])\n",
    "            datasetYSamples[sampleCount].append(stackedLabel[labelLocation][:sampleCount])\n",
    "    \n",
    "    fileSavePath = dirName+'/'+fineTuneDir+ '/'\n",
    "    os.makedirs(fileSavePath, exist_ok=True)\n",
    "    for sampleCount in fineTuneSamples:\n",
    "        hkl.dump(np.vstack((datasetXSamples[sampleCount])),fileSavePath + datasetList[index]+'_'+str(int(sampleCount))+'_samples_data.hkl')\n",
    "        hkl.dump(np.vstack((datasetYSamples[sampleCount])),fileSavePath + datasetList[index]+'_'+str(int(sampleCount))+'_samples_label.hkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
