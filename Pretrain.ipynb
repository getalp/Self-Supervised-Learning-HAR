{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-YuikCiP53N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hickle as hkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.manifold\n",
    "import copy\n",
    "import csv\n",
    "import __main__ as main\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "\n",
    "seed = 1\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwFHmiuFP53O"
   },
   "outputs": [],
   "source": [
    "# Library scripts\n",
    "import utils \n",
    "import training\n",
    "import data2vec_model\n",
    "import mae_model\n",
    "import simclr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentSetting = 'LODO'\n",
    "# 'LOGO','LODO'\n",
    "testingDataset = 'MotionSense'\n",
    "# 'HHAR','MobiAct','MotionSense','RealWorld_Waist','UCI','PAMAP'\n",
    "evaluationType = 'group'\n",
    "# 'subject','group'\n",
    "\n",
    "method = 'MAE'\n",
    "# Data2vec, MAE, SimCLR\n",
    "\n",
    "architecture = 'HART'\n",
    "\n",
    "finetune_epoch = 100\n",
    "\n",
    "finetune_batch_size = 64\n",
    "\n",
    "SSL_batch_size = 128\n",
    "\n",
    "loss = 'Adam'\n",
    "# 'LARS', 'Adam', 'SGD'\n",
    "\n",
    "SSL_LR = 3e-4\n",
    "\n",
    "FT_LR = 3e-4\n",
    "\n",
    "input_shape = (128,6)\n",
    "\n",
    "frame_length = 16\n",
    "\n",
    "SSL_epochs = 200\n",
    "\n",
    "masking_ratio = 75e-2\n",
    "\n",
    "instance_number = 0\n",
    "\n",
    "randomRuns = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['HHAR','MobiAct','MotionSense','RealWorld_Waist','UCI','PAMAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = ['HART','ISPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fit_args(parser):\n",
    "    \"\"\"\n",
    "    parser : argparse.ArgumentParser\n",
    "    return a parser added with args required by fit\n",
    "    \"\"\"\n",
    "    # Training settings\n",
    "    parser.add_argument('--experimentSetting', type=str, default=experimentSetting, \n",
    "        help='Leave one dataset out or Leave one group out')  \n",
    "    parser.add_argument('--testingDataset', type=str, default=testingDataset, \n",
    "        help='Left out dataset')  \n",
    "    parser.add_argument('--evaluationType', type=str, default=evaluationType, \n",
    "        help='Dataset group evaluation or subject by subject evaluation')  \n",
    "    parser.add_argument('--SSL_epochs', type=int, default=SSL_epochs, \n",
    "        help='SSL Epochs')  \n",
    "    parser.add_argument('--SSL_batch_size', type=int, default=SSL_batch_size, \n",
    "        help='SSL batch_size')  \n",
    "    parser.add_argument('--finetune_epoch', type=int, default=finetune_epoch, \n",
    "        help='Fine_tune Epochs')  \n",
    "    parser.add_argument('--loss', type=str, default=loss, \n",
    "        help='Specify the loss') \n",
    "    parser.add_argument('--SSL_LR', type=float, default=SSL_LR, \n",
    "        help='Specify the learning rate for the SSL techniques') \n",
    "    parser.add_argument('--masking_ratio', type=float, default=masking_ratio, \n",
    "        help='Specify the masking ratio') \n",
    "    parser.add_argument('--frame_length', type=int, default=frame_length, \n",
    "        help='Specify the masking ratio') \n",
    "    parser.add_argument('--architecture', type=str, default=architecture, \n",
    "        help='Specify the architecture of the model to train with') \n",
    "    parser.add_argument('--method', type=str, default=method, \n",
    "        help='Specify the SSL method') \n",
    "    parser.add_argument('--instance_number', type=int, default=instance_number, \n",
    "        help='Specify the SSL method') \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "def is_interactive():\n",
    "    return not hasattr(main, '__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(input_shape[0] % frame_length != 0 ):\n",
    "    raise Exception(\"Invalid segment size\")\n",
    "else:\n",
    "    patch_count = input_shape[0] // frame_length\n",
    "print(\"Number of segments : \"+str(patch_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = './'\n",
    "if not is_interactive():\n",
    "    args = add_fit_args(argparse.ArgumentParser(description='SSL Pretraining Pipeline'))\n",
    "    experimentSetting = args.experimentSetting\n",
    "    testingDataset = args.testingDataset\n",
    "    evaluationType = args.evaluationType\n",
    "    SSL_epochs = args.SSL_epochs\n",
    "    frame_length = args.frame_length\n",
    "    SSL_batch_size = args.SSL_batch_size\n",
    "    finetune_epoch = args.finetune_epoch\n",
    "    loss = args.loss\n",
    "    SSL_LR = args.SSL_LR\n",
    "    masking_ratio = args.masking_ratio\n",
    "    architecture = args.architecture\n",
    "    method = args.method\n",
    "    instance_number = args.instance_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sleep needed when launching jobs in parallel\n",
    "# time.sleep((instance_number % 30) * 20 ) \n",
    "# # remove this before public release\n",
    "# datasetIndex = (instance_number // (len(datasets) - 1)) % 6\n",
    "# architectureIndex = instance_number // 30\n",
    "# instance_number = instance_number%5\n",
    "# testingDataset = datasets[datasetIndex]\n",
    "# architecture = architectures[architectureIndex]\n",
    "# print(\"instance_number: \" +str(instance_number))\n",
    "# print(\"testingDataset: \" +str(datasets[datasetIndex]) + \" architecture: \" +str(architectures[architectureIndex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = rootdir+'Datasets/SSL_PipelineUnionV2/'+experimentSetting+'/'\n",
    "# projectName = str(architecture)+'_Data2Vec_LayerNorm_mask_'+str(masking_ratio)+'_frameLength_'+str(frame_length)+'_SSL_epochs_'+str(SSL_epochs)\n",
    "projectName = str(method) +\"_\"+str (architecture) + \"_SSL_Epochs\" + str(SSL_epochs)\n",
    "testMode = False\n",
    "if(finetune_epoch < 10):\n",
    "    testMode = True\n",
    "    projectName= projectName + '/tests'\n",
    "    \n",
    "dataSetting = testingDataset\n",
    "\n",
    "project_directory = rootdir+'results/'+projectName+'/'+str(instance_number)+'/'\n",
    "working_directory = project_directory+dataSetting+'/'\n",
    "pretrained_dir = working_directory + evaluationType + '/'\n",
    "    \n",
    "initWeightDir_pretrain = project_directory+'ini_'+str(method)+'_'+str(architecture)+'_Pretraining_Weights.h5'\n",
    "val_checkpoint_pipeline_weights = working_directory+\"best_val_\"+str(method)+\"_pretrain.h5\"\n",
    "trained_pipeline_weights = working_directory+\"trained_\"+str(method)+\"_pretrain.h5\"\n",
    "random_FT_weights = working_directory+\"ini_\"+str(method)+\"_HART_Classification_Weights.h5\"    \n",
    "trained_FT_weights = working_directory+\"trained_\"+str(method)+\"_dowmstream.h5\"\n",
    "\n",
    "os.makedirs(pretrained_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetList = [\"HHAR\",\"MobiAct\",\"MotionSense\",\"RealWorld_Waist\",\"UCI\",\"PAMAP\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSLdatasetList = copy.deepcopy(datasetList)\n",
    "SSLdatasetList.remove(testingDataset)\n",
    "SSL_data = []\n",
    "SSL_label = []\n",
    "\n",
    "SSL_val_data = []\n",
    "SSL_val_label = []\n",
    "\n",
    "for datasetName in SSLdatasetList:\n",
    "    SSL_data.append(hkl.load(dataDir + 'testData/'+str(datasetName)+'_data.hkl'))\n",
    "    SSL_data.append(hkl.load(dataDir + 'fineTuneData/'+str(datasetName)+'_all_samples_data.hkl'))\n",
    "    SSL_val_data.append(hkl.load(dataDir + 'valData/'+str(datasetName)+'_data.hkl'))\n",
    "\n",
    "SSL_data = np.vstack((np.hstack((SSL_data))))\n",
    "\n",
    "SSL_val_data = np.vstack((np.hstack((SSL_val_data))))\n",
    "\n",
    "testData = hkl.load(dataDir + 'testData/'+testingDataset+'_data.hkl')\n",
    "testLabel = hkl.load(dataDir + 'testData/'+testingDataset+'_label.hkl')\n",
    "\n",
    "valData = hkl.load(dataDir + 'valData/'+testingDataset+'_data.hkl')\n",
    "valLabel = hkl.load(dataDir + 'valData/'+testingDataset+'_label.hkl')\n",
    "\n",
    "testData = np.vstack((testData))\n",
    "testLabel = np.vstack((testLabel))\n",
    "valData = np.vstack((valData))\n",
    "valLabel = np.vstack((valLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are getting the labels presented only in the target dataset and calculating the suitable output shape.\n",
    "ALL_ACTIVITY_LABEL = np.asarray(['Downstairs', 'Upstairs','Running','Sitting','Standing','Walking','Lying','Cycling','Nordic_Walking','Jumping'])\n",
    "uniqueClassIDs = np.unique(np.argmax(testLabel,axis = -1))\n",
    "ACTIVITY_LABEL = ALL_ACTIVITY_LABEL[uniqueClassIDs]\n",
    "output_shape = len(ACTIVITY_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(method == 'Data2vec'):\n",
    "#     if(architecture == \"HART\"):\n",
    "#         enc_embedding_size = 192\n",
    "#         teacherEncoder = data2vec_model.HART_teacher_encoder(projection_dim = enc_embedding_size, num_heads = 3,\n",
    "#                                                 filterAttentionHead = 4, \n",
    "#                                                 convKernels = [3, 7, 15, 31, 31, 31],\n",
    "#                                                 layerAverage = 3)\n",
    "        \n",
    "#         studentEncoder = data2vec_model.HART_student_encoder(projection_dim = enc_embedding_size, num_heads = 3,\n",
    "#                                                 filterAttentionHead = 4, \n",
    "#                                                 convKernels = [3, 7, 15, 31, 31, 31],)\n",
    "        \n",
    "        \n",
    "#         sensorWiseFramer = data2vec_model.SensorWiseFrameLayer(frame_length,frame_length)\n",
    "#         sensorWiseMaskEncoder = data2vec_model.SensorWiseMaskEncoder(enc_embedding_size,masking_ratio,frame_length)\n",
    "#     elif(architecture == \"ISPL\"):        \n",
    "#         enc_embedding_size = 256\n",
    "#         teacherEncoder = data2vec_model.ispl_inception_teacher_encoder(enc_embedding_size)\n",
    "#         studentEncoder = data2vec_model.ispl_inception_encoder(enc_embedding_size)\n",
    "        \n",
    "#         sensorWiseFramer = data2vec_model.FrameLayer(frame_length,frame_length)\n",
    "#         # sensorWiseMaskEncoder = data2vec_model.MaskEncoder(enc_embedding_size,masking_ratio,frame_length)\n",
    "#         sensorWiseMaskEncoder = data2vec_model.MaskEncoder(enc_embedding_size,masking_ratio,frame_length)\n",
    "\n",
    "#     else:\n",
    "#         raise Exception(\"Unrecognized architecture, Please select one of the following: ISPL, HART,HART_BASE\")\n",
    "        \n",
    "#     pretrain_pipeline =  data2vec_model.Data2Vec(sensorWiseFramer,\n",
    "#                                          sensorWiseMaskEncoder,\n",
    "#                                          teacherEncoder,\n",
    "#                                          studentEncoder)   \n",
    "#     SSL_loss = tf.keras.losses.Huber()\n",
    "    \n",
    "#     pretrain_callbacks.append(data2vec_model.EMA())\n",
    "    \n",
    "#     for teacherLayers in teacherEncoder.layers:\n",
    "#         teacherLayers.trainable = False\n",
    "# elif(method == 'MAE'):\n",
    "#     if(architecture == \"HART\"):\n",
    "#         enc_embedding_size = 192\n",
    "#         patch_layer = mae_model.SensorWiseFrameLayer(frame_length,frame_length)\n",
    "#         patch_encoder = mae_model.SensorWisePatchEncoder(frame_length,enc_embedding_size,True,masking_ratio)    \n",
    "#         mae_encoder = mae_model.HART_encoder(enc_embedding_size,                                                     \n",
    "#                                              num_heads = 3,\n",
    "#                                              filterAttentionHead = 4, \n",
    "#                                              convKernels = [3, 7, 15, 31, 31, 31])\n",
    "\n",
    "#         mae_decoder = mae_model.HART_decoder(enc_embedding_size = enc_embedding_size,\n",
    "#                                              num_heads = 3,\n",
    "#                                              filterAttentionHead = 4, \n",
    "#                                              convKernels = [3, 7, 7, 15])\n",
    "#     elif(architecture == \"ISPL\"):\n",
    "# #         this parameter was hardcoded into ISPL for MAE to align with original author without changing the architecture.\n",
    "#         enc_embedding_size = 256\n",
    "#         dec_embedding_size = (enc_embedding_size//2)\n",
    "#         patch_layer = mae_model.PatchLayer(frame_length,frame_length)\n",
    "#         patch_encoder = mae_model.PatchEncoder(frame_length,enc_embedding_size,True,masking_ratio)    \n",
    "#         mae_encoder = mae_model.ispl_inception_encoder(enc_embedding_size)\n",
    "#         mae_decoder = mae_model.ispl_inception_decoder(enc_embedding_size,patch_count = patch_count,output_shape = input_shape)\n",
    "#     else:\n",
    "#         raise Exception(\"Unrecognized architecture, Please select one of the following: ISPL, HART,HART_BASE\")\n",
    "#     pretrain_pipeline = mae_model.MaskedAutoencoder(patch_layer,\n",
    "#                             patch_encoder,\n",
    "#                             mae_encoder,\n",
    "#                             mae_decoder)\n",
    "\n",
    "#     SSL_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "# elif(method == 'SimCLR'):\n",
    "#     if(architecture == \"HART\"):\n",
    "#         encoder = simclr_model.HART_encoder(input_shape)\n",
    "#     elif(architecture == \"ISPL\"):\n",
    "#         encoder = simclr_model.ispl_inception_encoder(input_shape)\n",
    "#     else:\n",
    "#         raise Exception(\"Unrecognized architecture, Please select one of the following: ISPL, HART,HART_BASE\")\n",
    "#     transform_funcs = [\n",
    "#         simclr_model.rotation_transform_vectorized # Use rotation trasnformation\n",
    "#     ]    \n",
    "#     projection_heads = simclr_model.projection_head(encoder.output.shape[1])\n",
    "#     transformations = simclr_model.generate_composite_transform_function_simple(transform_funcs)\n",
    "#     pretrain_pipeline = simclr_model.SimCLR(encoder,\n",
    "#                         projection_heads,\n",
    "#                         transformations)\n",
    "    \n",
    "# #     Custom loss already defined inside of training pipeline\n",
    "#     SSL_loss = simclr_model.NT_Xent_loss(temperature = 0.01)\n",
    "# else:\n",
    "#     raise Exception(\"Unrecognized algorithm, Please select one of the following: SimCLR, Data2vec, MAE\")\n",
    "# # ISPL,HART,MobileHART,DeepConvLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(method == 'Data2vec'):\n",
    "    if(architecture == \"HART\"):\n",
    "        enc_embedding_size = 192\n",
    "        teacherEncoder = data2vec_model.HART_teacher_encoder(projection_dim = enc_embedding_size, num_heads = 3,\n",
    "                                                filterAttentionHead = 4, \n",
    "                                                convKernels = [3, 7, 15, 31, 31, 31],\n",
    "                                                layerAverage = 3)\n",
    "        studentEncoder = data2vec_model.HART_student_encoder(projection_dim = enc_embedding_size, num_heads = 3,\n",
    "                                                filterAttentionHead = 4, \n",
    "                                                convKernels = [3, 7, 15, 31, 31, 31],)\n",
    "        sensorWiseFramer = data2vec_model.SensorWiseFrameLayer(frame_length,frame_length)\n",
    "        sensorWiseMaskEncoder = data2vec_model.SensorWiseMaskEncoder(enc_embedding_size,0.50,frame_length)\n",
    "        delta = 0.5\n",
    "        decay = 0.9999\n",
    "    elif(architecture == \"ISPL\"):        \n",
    "        enc_embedding_size = 256\n",
    "        teacherEncoder = data2vec_model.ispl_inception_teacher_encoder(enc_embedding_size)\n",
    "        studentEncoder = data2vec_model.ispl_inception_encoder(enc_embedding_size)\n",
    "        \n",
    "        sensorWiseFramer = data2vec_model.FrameLayer(frame_length,frame_length)\n",
    "        sensorWiseMaskEncoder = data2vec_model.MaskEncoder(enc_embedding_size,0.75,frame_length)\n",
    "        delta = 0.5\n",
    "        decay = 0.998\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Unrecognized architecture, Please select one of the following: ISPL, HART,HART_BASE\")\n",
    "        \n",
    "    pretrain_pipeline =  data2vec_model.Data2Vec(sensorWiseFramer,\n",
    "                                         sensorWiseMaskEncoder,\n",
    "                                         teacherEncoder,\n",
    "                                         studentEncoder)   \n",
    "    SSL_loss = tf.keras.losses.Huber(delta = delta)\n",
    "    \n",
    "    pretrain_callbacks.append(data2vec_model.EMA(decay = decay))\n",
    "    \n",
    "    for teacherLayers in teacherEncoder.layers:\n",
    "        teacherLayers.trainable = False\n",
    "elif(method == 'MAE'):\n",
    "    if(architecture == \"HART\"):\n",
    "        enc_embedding_size = 192\n",
    "        patch_layer = mae_model.SensorWiseFrameLayer(frame_length,frame_length)\n",
    "        patch_encoder = mae_model.SensorWisePatchEncoder(frame_length,enc_embedding_size,0.6)    \n",
    "        mae_encoder = mae_model.HART_encoder(enc_embedding_size,                                                     \n",
    "                                             num_heads = 3,\n",
    "                                             filterAttentionHead = 4, \n",
    "                                             convKernels = [3, 7, 15, 31, 31, 31])\n",
    "    \n",
    "        mae_decoder = mae_model.HART_decoder(enc_embedding_size = enc_embedding_size,\n",
    "                                             projection_dim = 256,\n",
    "                                             patch_count = patch_count,\n",
    "                                             num_heads = 3,\n",
    "                                             filterAttentionHead = 4, \n",
    "                                             convKernels = [3, 7, 15, 31, 31, 31])\n",
    "    elif(architecture == \"ISPL\"):\n",
    "        enc_embedding_size = 256\n",
    "    \n",
    "        patch_layer = mae_model.PatchLayer(frame_length,frame_length)\n",
    "        patch_encoder = mae_model.PatchEncoder(frame_length,enc_embedding_size,0.6)    \n",
    "        mae_encoder = mae_model.ispl_inception_encoder(enc_embedding_size)\n",
    "        mae_decoder = mae_model.ispl_inception_decoder(enc_embedding_size,\n",
    "                                                       patch_count = patch_count,\n",
    "                                                       filters_number = 192,\n",
    "                                                       network_depth = 4,\n",
    "                                                       output_shape = input_shape)\n",
    "    else:\n",
    "        raise Exception(\"Unrecognized architecture, Please select one of the following: ISPL, HART,HART_BASE\")\n",
    "    pretrain_pipeline = mae_model.MaskedAutoencoder(patch_layer,\n",
    "                            patch_encoder,\n",
    "                            mae_encoder,\n",
    "                            mae_decoder)\n",
    "\n",
    "    SSL_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "elif(method == 'SimCLR'):\n",
    "    transform_funcs = []\n",
    "    if(architecture == \"HART\"):\n",
    "        encoder = simclr_model.HART_encoder(input_shape)\n",
    "        transform_funcs.append(simclr_model.noise_transform_vectorized)\n",
    "\n",
    "    elif(architecture == \"ISPL\"):\n",
    "        encoder = simclr_model.ispl_inception_encoder(input_shape)\n",
    "        transform_funcs.append(simclr_model.rotation_transform_vectorized)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Unrecognized architecture, Please select one of the following: ISPL, HART,HART_BASE\")\n",
    "    projection_heads = simclr_model.projection_head(encoder.output.shape[1])       \n",
    "    transformations = simclr_model.generate_composite_transform_function_simple(transform_funcs)    \n",
    "    pretrain_pipeline = simclr_model.SimCLR(encoder,\n",
    "                        projection_heads,\n",
    "                        transformations)\n",
    "#     Custom loss already defined inside of training pipeline\n",
    "    SSL_loss = simclr_model.NT_Xent_loss(temperature = 0.1)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Unrecognized algorithm, Please select one of the following: SimCLR, Data2vec, MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(SSL_LR)\n",
    "\n",
    "pretrain_pipeline.compile(optimizer=optimizer, loss=SSL_loss, metrics=[])\n",
    "\n",
    "# Forcing a build to the model \n",
    "pretrain_pipeline.build(input_shape = (None,128,6))\n",
    "\n",
    "if(not os.path.exists(initWeightDir_pretrain)):\n",
    "    print(\"Initialized model weights not found, generating one\")\n",
    "    pretrain_pipeline.save_weights(initWeightDir_pretrain)\n",
    "else:\n",
    "    pretrain_pipeline.load_weights(initWeightDir_pretrain)\n",
    "    print(\"Initialized model weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_FE = pretrain_pipeline.return_feature_extrator()\n",
    "classification_model = utils.create_classification_model_from_base_model(pretrained_FE,output_shape,model_name = \"pretrain_pipeline_classifier\")\n",
    "FE_Layers = len(pretrained_FE.layers) + 1\n",
    "if(not os.path.exists(random_FT_weights)):\n",
    "    classification_model.save_weights(random_FT_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(not os.path.exists(trained_pipeline_weights)):\n",
    "    print(trained_pipeline_weights)\n",
    "    print(\"Not Found\")\n",
    "    best_val_model_callback = tf.keras.callbacks.ModelCheckpoint(val_checkpoint_pipeline_weights,\n",
    "    monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True, verbose=2)\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    pretrain_callbacks.append(best_val_model_callback)\n",
    "    pretrain_callbacks.append(stop_early)\n",
    "    history = pretrain_pipeline.fit(SSL_data,\n",
    "                                    validation_data = (SSL_val_data,SSL_val_data), \n",
    "                                    batch_size = SSL_batch_size, \n",
    "                                    epochs = SSL_epochs,\n",
    "                                    callbacks=pretrain_callbacks,\n",
    "                                    verbose=2)\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(history.history['loss'], label = 'Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'Val Loss')\n",
    "    plt.plot(history.history['val_loss'],markevery=[np.argmin(history.history['val_loss'])], ls=\"\", marker=\"o\",color=\"orange\")\n",
    "    plt.plot(history.history['loss'],markevery=[np.argmin(history.history['loss'])], ls=\"\", marker=\"o\",color=\"blue\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.savefig(working_directory+\"lossCurve.png\", bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "    pretrain_pipeline.load_weights(val_checkpoint_pipeline_weights)\n",
    "    pretrain_pipeline.save_weights(trained_pipeline_weights)\n",
    "    classification_model.save_weights(trained_FT_weights)\n",
    "    perplexity = 30.0\n",
    "    embeddings = pretrain_pipeline.predict(testData, batch_size=1024,verbose=0)\n",
    "    tsne_model = sklearn.manifold.TSNE(perplexity=perplexity, verbose=0, random_state=42)\n",
    "    tsne_projections = tsne_model.fit_transform(embeddings)\n",
    "    labels_argmax = np.argmax(testLabel, axis=1)\n",
    "    unique_labels = np.unique(labels_argmax)\n",
    "    utils.projectTSNE('TSNE_Embeds',pretrained_dir,ALL_ACTIVITY_LABEL,labels_argmax,tsne_projections,unique_labels )\n",
    "    utils.projectTSNEWithShape('TSNE_Embeds_shape',pretrained_dir,ALL_ACTIVITY_LABEL,labels_argmax,tsne_projections,unique_labels )\n",
    "    hkl.dump(tsne_projections,pretrained_dir+'tsne_projections.hkl')\n",
    "else:\n",
    "    pretrain_pipeline.load_weights(trained_pipeline_weights)\n",
    "    classification_model.load_weights(trained_FT_weights)\n",
    "    print(\"Pre-trained model found, skipping training of pretrained model\",flush = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMELGS4VP53U"
   },
   "source": [
    "### Downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['1','2', '5', '10', '25', '50', '100','all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotSizeAdjuster(oneHotLabels):\n",
    "    argmaxsLabels = np.argmax(oneHotLabels,axis = -1)\n",
    "    for newLabel,oldLabel in enumerate(np.unique(argmaxsLabels)):\n",
    "        argmaxsLabels[argmaxsLabels == oldLabel ] = newLabel\n",
    "    return tf.one_hot(argmaxsLabels,output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valLabel = utils.oneHotSizeAdjuster(valLabel,output_shape)\n",
    "testLabel = utils.oneHotSizeAdjuster(testLabel,output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleResult = {}\n",
    "for sampleCount in samples:\n",
    "    print(\"Now downstreaming on \"+testingDataset+\" dataset with samples count: \"+str(sampleCount), flush = True)\n",
    "    evaluation_dir = pretrained_dir+'samples_'+ str(sampleCount) + '/'\n",
    "    os.makedirs(evaluation_dir, exist_ok=True)\n",
    "    fineTuneData,fineTuneLabel = utils.loadFineTuneData(sampleCount,testingDataset,dataDir)\n",
    "    fineTuneLabel = utils.oneHotSizeAdjuster(fineTuneLabel,output_shape)\n",
    "    evaluationsF1 = training.downStreamPipeline(fineTuneData,fineTuneLabel,valData,valLabel,testData,testLabel,\n",
    "                                                evaluation_dir,\n",
    "                                                classification_model,\n",
    "                                                FE_Layers,random_FT_weights,trained_FT_weights,\n",
    "                                                finetune_epoch = finetune_epoch, \n",
    "                                                finetune_batch_size = finetune_batch_size)\n",
    "    sampleResult['sample_'+str(sampleCount)] = evaluationsF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRatio = np.asarray(list(sampleResult.values())).T\n",
    "evaluationMethods = ['Result_Frozen_FE','Result_Unfrozen_FE']\n",
    "for evalIndex, methods in enumerate(evaluationMethods):\n",
    "    toWriteEvaluation = {}\n",
    "    toWriteEvaluation['dataset'] = [testingDataset]\n",
    "    for ratioIndex, sample in enumerate(samples):\n",
    "        toWriteEvaluation['Sample_'+str(sample)] = [npRatio[evalIndex][ratioIndex]]\n",
    "    tabular = tabulate(toWriteEvaluation, headers=\"keys\")\n",
    "    print(methods)\n",
    "    print(tabular)\n",
    "    print()\n",
    "    text_file = open(pretrained_dir +methods+'_report.csv',\"w\")\n",
    "    text_file.write(tabular)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTrained = True \n",
    "for methods in evaluationMethods:\n",
    "    print(\"Processing \"+str(methods) +\" report\")\n",
    "    fullReport = []\n",
    "    ratioHeaders = ['Sample_'+str(sample) for sample in samples]\n",
    "    ratioHeaders.insert(0, \"dataset\")\n",
    "    fullReport.append(ratioHeaders)\n",
    "    if(allTrained):\n",
    "        for datasetName in datasetList:\n",
    "            checkDir = rootdir+'results/'+projectName+'/'+datasetName+'/'+evaluationType+'/'+methods+\"_report.csv\"\n",
    "            if(not os.path.exists(checkDir)):\n",
    "                print(\"Dir below not found:\")\n",
    "                print(checkDir)\n",
    "                allTrained = False\n",
    "                break\n",
    "            readData = pd.read_table(checkDir, delim_whitespace=True)\n",
    "            fullReport.append(readData.to_numpy()[1])\n",
    "    else:\n",
    "        break\n",
    "    if(allTrained):\n",
    "        print(\"Generating \"+str(methods) + \" report\")\n",
    "        tabular2 = tabulate(fullReport)\n",
    "        text_file = open(rootdir+'results/'+projectName+'/'+str(evaluationType)+'_'+str(methods)+'_report.csv',\"w\")\n",
    "        text_file.write(tabular2)\n",
    "        text_file.close()\n",
    "        print(tabular2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedResults = np.asarray(list(sampleResult.values())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkl.dump(formattedResults,working_directory+'training_results.hkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "SimCLR_MotionSense.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
